r"""
Distributed/Paralell computations using RecursivelyEnumeratedSet and Map-Reduce

There exists an easy way to distribute computations when you have a set `S` of
objects defined by a :class:`RecursivelyEnumeratedSet` object (see
:mod:`sage.combinat.backtrack` for more details) over which you would like to
perform the following kind of operations :

* Compute the cardinality of a (very large) set defined recursively
  (i.e. through a :class:`RecursivelyEnumeratedSet` object)

* Compute any kind of generating series over this set

* Test a conjecture : i.e. find an element of `S` satisfying a specific
  property, or check that all of them do

* Count/list the elements of `S` having this property

* Apply any map/reduce kind of operation over the elements of `S`

AUTHORS :

- Jean Baptiste Priez -- prototype (2011, June)

- Florent Hivert -- cleanup, server/manager/documentation (2012, September)

- Nathann Cohen -- Some doc (2012)

How is this different from what one can already do with MapReduce ?
-------------------------------------------------------------------

This implementation is specific to :class:`RecursivelyEnumeratedSet`, and uses its
properties to do its job. Hence, it is better to distribute computations
through this interface than using MapReduce on the elements of `S`, because
**generating the list of members of** `S` **is done on different
processors**. If most of the time is spent computing the elements of `S`, that
is a big step ahead.

How can I use all that stuff?
-----------------------------

First, you need the information necessary to describe a :class:`RecursivelyEnumeratedSet`
representing your set `S` (see :mod:`this module
<sage.combinat.backtrack>`). Then, you need to provide a Map function as well
as a Reduce function. Here are some examples :

* **Counting the number of elements** : In this situation, the map function
  can be set to ``lambda x : 1``, and the reduct function just adds the
  elements together, i.e. ``lambda x,y : x+y``.

  Here's the Sage code for binary words of length `\leq 16` ::

      sage: S = RecursivelyEnumeratedSet(
      ....:   [[]], lambda l: [l+[0], l+[1]] if len(l) <= 15 else [],
      ....:   structure='forest', enumeration='depth')
      sage: S.map_reduce(
      ....:   map_function = lambda x: 1,
      ....:   reduce_function = lambda x,y: x+y,
      ....:   reduce_init = 0 )
      131071

  Note that the function mapped and reduced here are equivalent to the default
  values of the :meth:`RecursivelyEnumeratedSet.map_reduce` method so that to compute the
  number of element you only need to call::

      sage: S.map_reduce()
      131071

  You don't need to use :class:`RecursivelyEnumeratedSet`, you can use directly
  :class:`RESetMapReduce`. This is needed if you want to have fine
  control over the parallel execution (see :ref:`advanced-use` below)::

      sage: from sage.combinat.map_reduce import RESetMapReduce
      sage: S = RESetMapReduce(
      ....:   roots = [[]],
      ....:   children = lambda l: [l+[0], l+[1]] if len(l) <= 15 else [],
      ....:   map_function = lambda x : 1,
      ....:   reduce_function = lambda x,y: x+y,
      ....:   reduce_init = 0 )
      sage: S.run()
      131071
      sage: factor(131071 + 1)
      2^17

* **Generating series** : In this situation, the map function associates a
  monomial to each element of `S`, while the Reduce function is still equal to
  ``lambda x,y : x+y``.

  Here's the Sage code for binary words of length `\leq 16` ::

      sage: S = RecursivelyEnumeratedSet(
      ....:   [[]], lambda l: [l+[0], l+[1]] if len(l) < 16 else [],
      ....:   structure='forest', enumeration='depth')
      sage: sp = S.map_reduce(
      ....:   map_function = lambda z: x**len(z),
      ....:   reduce_function = lambda x,y: x+y,
      ....:   reduce_init = 0 )
      sage: sp
      65536*x^16 + 32768*x^15 + 16384*x^14 + 8192*x^13 + 4096*x^12 + 2048*x^11 + 1024*x^10 + 512*x^9 + 256*x^8 + 128*x^7 + 64*x^6 + 32*x^5 + 16*x^4 + 8*x^3 + 4*x^2 + 2*x + 1

  This is of course `\sum_{i=0}^{i=16} (2x)^i`::

      sage: bool(sp == sum((2*x)^i for i in range(17)))
      True

  For permutations of size `\leq 8` (here we use the default values)::

      sage: S = RecursivelyEnumeratedSet( [[]],
      ....:   lambda l: ([l[:i] + [len(l)] + l[i:] for i in range(len(l)+1)]
      ....:               if len(l) < 8 else []),
      ....:   structure='forest', enumeration='depth')
      sage: sp = S.map_reduce(lambda z: x**len(z)); sp
      40320*x^8 + 5040*x^7 + 720*x^6 + 120*x^5 + 24*x^4 + 6*x^3 + 2*x^2 + x + 1

  This is of course `\sum_{i=0}^{i=8} i! x^i`::

      sage: bool(sp == sum(factorial(i)*x^i for i in range(9)))
      True

* On can also compute the list of objects in a :class:`RecursivelyEnumeratedSet` using
  :class:`RESetMapReduce`. As an example, we compute the set of number
  beetween 1 and 63, generated by their binary expansion::

      sage: S = RecursivelyEnumeratedSet( [1],
      ....:    lambda l: [(l<<1)|0, (l<<1)|1] if l < 1<<5 else [],
      ....:    structure='forest', enumeration='depth')

  Here is the list computed without :class:`RESetMapReduce`::

      sage: serial = list(S)
      sage: serial
      [1, 2, 4, 8, 16, 32, 33, 17, 34, 35, 9, 18, 36, 37, 19, 38, 39, 5, 10, 20, 40, 41, 21, 42, 43, 11, 22, 44, 45, 23, 46, 47, 3, 6, 12, 24, 48, 49, 25, 50, 51, 13, 26, 52, 53, 27, 54, 55, 7, 14, 28, 56, 57, 29, 58, 59, 15, 30, 60, 61, 31, 62, 63]

  Here is ahow to perform the parallel computation. The order of the lists
  depends on the synchronisation of the various computation processes and
  therefore should be considered as random::

      sage: parall = S.map_reduce( lambda x: [x], lambda x,y: x+y, [] )
      sage: parall   # random
      [1, 3, 7, 15, 31, 63, 62, 30, 61, 60, 14, 29, 59, 58, 28, 57, 56, 6, 13, 27, 55, 54, 26, 53, 52, 12, 25, 51, 50, 24, 49, 48, 2, 5, 11, 23, 47, 46, 22, 45, 44, 10, 21, 43, 42, 20, 41, 40, 4, 9, 19, 39, 38, 18, 37, 36, 8, 17, 35, 34, 16, 33, 32]
      sage: sorted(serial) == sorted(parall)
      True

.. _advanced-use:

Advanced use
------------

**Florent :**

- Explication de postprocess

- Comment lancer des serveurs distants

- parametres avances de distribution

Remarques
---------

- Postprocess et map, finalement, ca ne fait pas la meme chose ?

- Hey... On peut deja faire du mapreduce distribue dans Sage ou meme pas ? Si
  c'est le cas il faut mettre des pointeurs, sinon il faut resoudre le probleme
  ! Y'a surement deja une lib pour ca d'ailleurs.

Tests
-----

Generating series for sum of strictly decreassing list of integer smaller than
15::

    sage: y = var('y')
    sage: R = RESetMapReduce(
    ....:  roots = [([], 0, 0)] +[([i], i, i) for i in range(1,15)],
    ....:  children = lambda (list, sum, last):
    ....:      [(list + [i], sum + i, i) for i in range(1,last)],
    ....:  map_function = lambda (li, sum, unused): y**sum)
    sage: sg = R.run()
    sage: bool(sg == expand(prod((1+y^i) for i in range(1,15))))
    True


Classes and methods
-------------------
"""
from multiprocessing import Process, Value, Event, Condition, Semaphore, Lock, cpu_count
from multiprocessing.queues import Pipe, SimpleQueue
from multiprocessing.sharedctypes import RawArray
from threading import Thread
from sage.sets.recursively_enumerated_set import RecursivelyEnumeratedSet # _generic
from sage.misc.lazy_attribute import lazy_attribute
import collections, copy, sys, random, ctypes, time, os

paralell_profile = None
# paralell_profile = "/tmp/profile_"

import logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.WARN)
#logger.setLevel(logging.INFO)
#logger.setLevel(logging.DEBUG)
ch = logging.StreamHandler()
ch.setLevel(logging.DEBUG)
formatter = logging.Formatter(
    '[%(processName)s] (%(asctime)s.%(msecs)03.f) %(message)s',
    datefmt='%H:%M:%S')
ch.setFormatter(formatter)
logger.addHandler(ch)



def proc_number(max_proc = None):
    r"""
    TESTS::

        sage: from sage.combinat.map_reduce import proc_number
        sage: proc_number() # random
        8
        sage: proc_number(max_proc=1)
        1
        sage: proc_number(max_proc=2) in (1, 2)
        True
    """
    if max_proc is None:
        return max(cpu_count(), 1)
    else:
        return min(max_proc, max(cpu_count(), 1))


class AbortError(Exception):
    r"""
    Exception for aborting parallel computations

    TESTS::

        sage: from sage.combinat.map_reduce import AbortError
        sage: raise AbortError
        Traceback (most recent call last):
        ...
        AbortError
    """
    pass


class RESetMapReduce(object):
    r"""
    Description of the protocol:

    TODO
    """
    def __init__(self, roots = None,
                 children = None,
                 post_process = None,
                 map_function = None,
                 reduce_function = None,
                 reduce_init = None,
                 forest = None):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: R = RESetMapReduce( [[]], lambda : [[]])
            sage: R
            <sage.combinat.map_reduce.RESetMapReduce object at 0x...>

        To silence the coverage checker::

            sage: TestSuite(R).run(skip=['_test_pickling'])
        """
        if forest is not None:
            if not all(x is None for x in (roots, children, post_process)):
                raise ValueError, "forest arg is incompatible with roots, children and post_process"
            self._forest = forest
            self._roots = forest._roots
            self.children = forest.children
            if hasattr(forest, 'post_process'):
                self.post_process = forest.post_process
        else:
            if roots is not None: self._roots = roots
            if children is not None: self.children = children
            if post_process is not None: self.post_process = post_process
        if map_function is not None: self.map_function = map_function
        if reduce_function is not None: self.reduce_function = reduce_function
        if reduce_init is not None: self._reduce_init = reduce_init

    @lazy_attribute
    def _forest(self):
        r"""

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: EX = RESetMPExample()
            sage: f = EX._forest; f
            An enumerated set with a forest structure
            sage: f.an_element()
            []
        """
        return RecursivelyEnumeratedSet(
            self.roots(),
            self.children,
            post_process=self.post_process,
            structure='forest', enumeration='depth')


    def roots(self):
        r"""
        Return the roots of ``self``
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce(42)
            sage: S.roots()
            42
        """
        return self._roots

    def map_function(self, o):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce()
            sage: S.map_function(7)
            1
            sage: S = RESetMapReduce(map_function = lambda x: 3*x + 5)
            sage: S.map_function(7)
            26
         """
        return 1

    def reduce_function(self, a, b):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce()
            sage: S.reduce_function(4, 3)
            7
            sage: S = RESetMapReduce(reduce_function=lambda x,y: x*y)
            sage: S.reduce_function(4, 3)
            12
        """
        return a+b

    def post_process(self, a):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce()
            sage: S.post_process(4)
            4
            sage: S = RESetMapReduce(post_process=lambda x: x*x)
            sage: S.post_process(4)
            16
        """
        return a


    _reduce_init = 0

    def reduce_init(self):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce()
            sage: S.reduce_init()
            0
            sage: S = RESetMapReduce(reduce_init = 2)
            sage: S.reduce_init()
            2
        """
        return copy.copy(self._reduce_init)


    def setup_workers(self, max_proc = None, reduce_locally=True):
        r"""
        Setup the communication channels

        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce()
            sage: S.setup_workers(2)
            sage: S._results
            <multiprocessing.queues.SimpleQueue object at 0x...>
            sage: len(S._workers)
            2
        """
        self._nprocess = proc_number(max_proc)
        self._results = SimpleQueue()
        self._active_tasks = Semaphore(self._nprocess)
        self._done = Lock()
        self._abort = Value(ctypes.c_bool, False)
        sys.stdout.flush()
        sys.stderr.flush()
        self._workers = [MapReduceWorker(self, i, reduce_locally)
                         for i in range(self._nprocess)]

    def start_workers(self):
        r"""
        Lauch the workers

        Local and remote worker should have been created.

        TESTS::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce(roots=[])
            sage: S.setup_workers(2)
            sage: S.start_workers()
            sage: all(w.is_alive() for w in S._workers)
            True

            sage: sleep(1)
            sage: all(not w.is_alive() for w in S._workers)
            True

        Cleanups::

            sage: S.finish()
        """
        if self._nprocess == 0:
            raise ValueError, "No process connected"
        logger.info("Starting work with %s processes", self._nprocess)
        logger.debug("Distributing tasks")
        for i, task in enumerate(self.roots()):
            # os.write(0, "Adding task = %s"%task)
            self._workers[i % len(self._workers)]._todo.append(task)
        logger.debug("Starting processes")
        sys.stdout.flush()
        sys.stderr.flush()
        for w in self._workers: w.start()

    def get_results(self):
        r"""
        Get the results from the queue

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMapReduce
            sage: S = RESetMapReduce()
            sage: S.setup_workers(2)
            sage: for v in [1, 2, None, 3, None]: S._results.put(v)
            sage: S.get_results()
            6

        Cleanups::

            sage: del S._results, S._active_tasks, S._done, S._workers
        """
        res = self.reduce_init()
        active_proc = self._nprocess
        while active_proc > 0:
            newres = self._results.get()
            if newres is not None:
                logger.debug("Got one result")
                res = self.reduce_function(res, newres)
            else:
                active_proc -= 1
        return res


    def finish(self):
        r"""
        Cleanup

        TESTS::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: S = RESetMPExample(maxl=5)
            sage: S.setup_workers(2) # indirect doctest
            sage: S._workers[0]._todo.append([])
            sage: for w in S._workers: w.start()
            sage: S._shutdown()
            sage: S.finish()

        Cleanups::

            sage: _ = S.run()
        """
        self._abort = self._abort.value
        if not self._abort:
            logger.debug("Joining worker processes...")
            for worker in self._workers:
                logger.debug("Joining %s"%worker.name)
                worker.join()
            logger.debug("Joining done")
        else:
            logger.debug("Killing worker processes...")
            for worker in self._workers:
                logger.debug("Terminating %s"%worker.name)
                worker.terminate()
            logger.debug("Killing done")

        del self._results, self._active_tasks, self._done
        self._get_stats()
        del self._workers


    def abort(self):
        r"""
        Abort the current parallel computation

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetParallelIterator
            sage: S = RESetParallelIterator( [[]],
            ....:   lambda l: [l+[0], l+[1]] if len(l) < 17 else [])
            sage: it = iter(S)
            sage: it.next()
            []
            sage: S.abort()
            sage: hasattr(S, 'work_queue')
            False

        Cleanups::

            sage: S.finish()
        """
        logger.info("Aborting")
        # os.write(0, " Abort !\n")
        self._abort.value = True
        while self._active_tasks.acquire(False):
            pass
        self._shutdown()

    def _shutdown(self):
        r"""
        Calling to shutdown the workers

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetParallelIterator
            sage: S = RESetParallelIterator( [[]],
            ....:   lambda l: [l+[0], l+[1]] if len(l) < 20 else [])
            sage: S.setup_workers(2)
            sage: for w in S._workers: w.start()
            sage: S._shutdown()

        Cleanups::

            sage: S.finish()
        """
        if self._done.acquire(False):
            # os.write(0, " Shutdown !\n")
            logger.debug("***************** FINISHED ******************")
            logger.debug("Sending poison pills")
            for worker in self._workers:
                worker._request.put(AbortError)
            for worker in self._workers:
                worker._write_task.send(AbortError)

    def _signal_task_start(self):
        r"""
        Signal a starting task

        Used by the worker to signal that a new task is starting. As soon as
        there are no more active task, the work is done, in which case an
        :exc:`AbortError` is raised.

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetParallelIterator
            sage: S = RESetParallelIterator( [[]],
            ....:   lambda l: [l+[0], l+[1]] if len(l) < 20 else [])
            sage: S.setup_workers(2)
            sage: S._active_tasks
            <Semaphore(value=2)>

            sage: S._signal_task_start()
            sage: S._active_tasks
            <Semaphore(value=3)>
        """
        if self._active_tasks._semlock._is_zero():
            raise AbortError
        self._active_tasks.release()

    def _signal_task_done(self):
        r"""
        Signal a done task

        Used by the worker to signal that a task is done. As soon as
        there are no more active task, the work is done, in which case an
        :exc:`AbortError` is raised.


        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetParallelIterator
            sage: S = RESetParallelIterator( [[]],
            ....:   lambda l: [l+[0], l+[1]] if len(l) < 20 else [])
            sage: S.setup_workers(2)
            sage: S._active_tasks
            <Semaphore(value=2)>

            sage: S._signal_task_done()
            sage: S._active_tasks
            <Semaphore(value=1)>

            sage: S._signal_task_done()
            Traceback (most recent call last):
            ...
            AbortError

        Cleanups::

            sage: del S._results, S._active_tasks, S._done, S._workers
        """
        if not self._active_tasks.acquire(False):
            raise AbortError
        if self._active_tasks._semlock._is_zero():
            self._shutdown()
            raise AbortError

    def random_worker(self):
        r"""
        Returns a random workers

        EXAMPLES:

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: from threading import Thread
            sage: EX = RESetMPExample(maxl=6)
            sage: EX.setup_workers(2)
            sage: EX.random_worker()
            <MapReduceWorker(MapReduceWorker-..., initial)>
            sage: EX.random_worker() in EX._workers
            True

        Cleanups::

            sage: del EX._results, EX._active_tasks, EX._done, EX._workers
        """
        victim = random.randint(0, len(self._workers)-1)
        return self._workers[victim]

    def run(self,
            max_proc = None,
            reduce_locally = True, print_stats=False, timeout=None):
        r"""
        Run the computations

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: EX = RESetMPExample(maxl = 4)
            sage: EX.run()
            24*x^4 + 6*x^3 + 2*x^2 + x + 1

            sage: EX.run(print_stats=True)  # random
            #proc:        0    1    2    3    4    5    6    7
            reqs sent:    5    1    5    4    5    9    3    0
            reqs rcvs:    2    4    5    5    1    3    5    1
            - thefs:      0    0    0    0    0    0    0    0
            + thefs:      0    0    0    0    0    0    0    0
            24*x^4 + 6*x^3 + 2*x^2 + x + 1
        """
        self.setup_workers(max_proc, reduce_locally)
        self.start_workers()
        if timeout is not None:
            from threading import Timer
            timer = Timer(timeout, self.abort)
            timer.start()
        self.result = self.get_results()
        self.finish()
        if timeout is not None:
            timer.cancel()
        if print_stats: print self.communication_statistics()
        logger.info("Returning")
        if self._abort:
            raise AbortError
        else:
            return self.result

    def _get_stats(self):
        r"""
        Gather the communication statistics and the end of a run

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: S = RESetMPExample(maxl=6)
            sage: S.run() # indirect doctest
            720*x^6 + 120*x^5 + 24*x^4 + 6*x^3 + 2*x^2 + x + 1
        """
        res = []
        for i in range(self._nprocess):
            res.append(tuple(self._workers[i]._stats))
        self._stats = res

    def communication_statistics(self, blocksize = 16):
        r"""
        Print the communication statistics in a nice way

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: S = RESetMPExample(maxl=6)
            sage: S.run()
            720*x^6 + 120*x^5 + 24*x^4 + 6*x^3 + 2*x^2 + x + 1

            sage: print(S.communication_statistics())    # random
            #proc:        0    1    2    3    4    5    6    7
            reqs sent:    2   11    8    2    5    1    2    0
            reqs rcvs:    3    2    1    7    2    5    4    1
            - thefs:      0    0    0    0    0    0    0    0
            + thefs:      0    0    0    0    0    0    0    0
        """
        res = [""]
        def pstat(name, start, end, ist):
            res[0] += "\n" + name
            res[0] += " ".join(
                "%4i"%(self._stats[i][ist]) for i in range(start, end))
        for start in range(0, self._nprocess, blocksize):
            end = min(start+blocksize, self._nprocess)
            res[0] = "#proc:     "+" ".join("%4i"%(i) for i in range(start, end))
            pstat("reqs sent: ", start, end, 0)
            pstat("reqs rcvs: ", start, end, 1)
            pstat("- thefs:   ", start, end, 2)
            pstat("+ thefs:   ", start, end, 3)
        return res[0]

    def run_serial(self):
        r"""
        Serial run of the computation (mostly for tests)

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: EX = RESetMPExample(maxl = 4)
            sage: EX.run_serial()
            24*x^4 + 6*x^3 + 2*x^2 + x + 1
        """
        import functools
        return functools.reduce(self.reduce_function,
                                (self.map_function(x) for x in self._forest),
                                self.reduce_init())


class MapReduceWorker(Process):
    """
    Worker for generate-map-reduce

    This shouldn't be called directly

    INPUT:

    - ``mapred`` -- the instance of :class:`RESetMapReduce` for which
      this process is working.

    - ``syncnodes`` -- how often worker synchronize with the other. The worker
      will synchronize every ``syncnodes`` processed nodes. The optimal value
      depend on the ratio communication time over time needed for processing
      one node.

    - ``reduce_locally`` -- when reducing the results. Three possible values
      are supported:

      * ``True`` -- means the reducing work is done all locally, the result is
        only sent back at the end of the work. This ensure the lowest level of
        communication.

      * ``False`` -- results are sent back after each finished branches, when
        the process is asking for more work.

      * ``sync`` -- results are sent back at every synchronization, so that
        the master receive partial results very often, at the expense of a lot
        of communications.
    """
    def __init__(self, mapred, i, reduce_locally):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: EX = RESetMPExample()
            sage: MapReduceWorker(EX, 200, True)
            <MapReduceWorker(MapReduceWorker-..., initial)>
        """
        Process.__init__(self)
        self._iproc = i
        self._todo = collections.deque()
        self._request = SimpleQueue()  # Faster than Queue
        # currently this is not possible to have to simultaneous read or write
        # on the following Pipe. So there is no need to have a queue.
        self._read_task, self._write_task = Pipe(duplex=False)
        self._mapred = mapred
        self._stats  =  RawArray('i', 4)
        self._reduce_locally = reduce_locally

    def _thief(self):
        r"""
        The thief thread of a worker process

        EXAMPLES:

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: from threading import Thread
            sage: EX = RESetMPExample(maxl=6)
            sage: EX.setup_workers(2)

            sage: w0, w1 = EX._workers
            sage: w0._todo.append(42)
            sage: thief0 = Thread(target = w0._thief, name="Thief")
            sage: thief0.start()

            sage: w1.steal()
            42
            sage: w0._todo
            deque([])
        """
        logger.debug("Thief started")
        reqs = 0
        thefts = 0

        try:
            for ireq in iter(self._request.get, AbortError):
                reqs +=1
                target = self._mapred._workers[ireq]
                logger.debug("Got a Steal request from %s"%target.name)
                self._mapred._signal_task_start()
                try:
                    work = self._todo.popleft()
                except IndexError:
                    target._write_task.send(None)
                    self._mapred._signal_task_done()
                    # os.write(0, "-")
                    # sys.stdout.flush()
                else:
                    target._write_task.send(work)
                    logger.debug("Succesful Steal %s"%target.name)
                    thefts += 1
                    # os.write(0, "+")
                    # sys.stdout.flush()
        except AbortError:
            logger.debug("Thief aborted %s"%self.name)
            pass
        if self._mapred._abort.value:
            self._todo.clear()
        else:
            assert len(self._todo) == 0, "Bad stop the result may be wrong"

        self._stats[1] = reqs
        self._stats[2] = thefts
        logger.debug("Thief Exiting")

    def steal(self):
        r"""
        Steal some node from another worker

        EXAMPLES:

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: from threading import Thread
            sage: EX = RESetMPExample(maxl=6)
            sage: EX.setup_workers(2)

            sage: w0, w1 = EX._workers
            sage: w0._todo.append(42)
            sage: thief0 = Thread(target = w0._thief, name="Thief")
            sage: thief0.start()

            sage: w1.steal()
            42
        """
        self._mapred._signal_task_done()
        node = None
        while node is None:
            victim = self._mapred.random_worker()
            if victim is not self:
                logger.debug("Trying to steal from %s"%(victim.name))
                victim._request.put(self._iproc)
                self._stats[0] += 1
                logger.debug("waiting from steal answer from %s"%(victim.name))
                node = self._read_task.recv()
                if node is AbortError:
                    raise AbortError
                logger.debug("Request answer: %s"%(node,))
        logger.debug("Node stolen: %s"%(node,))
        self._stats[3] += 1
        return node

    def run(self):
        r"""
        EXAMPLES:

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: EX = RESetMPExample(maxl=6)
            sage: EX.setup_workers(1)

            sage: w = EX._workers[0]
            sage: w._todo.append(EX.roots()[0])

            sage: w.run()
            sage: sleep(1)
            sage: w._todo.append(None)

            sage: EX.get_results()
            720*x^6 + 120*x^5 + 24*x^4 + 6*x^3 + 2*x^2 + x + 1

        Cleanups::

            sage: del EX._results, EX._active_tasks, EX._done, EX._workers
        """
        if paralell_profile:
            from multiprocessing import current_process
            import cProfile
            PROFILER = cProfile.Profile()
            PROFILER.runcall(self.run_myself)
            output = paralell_profile + current_process().name
            logger.warn("Profiling in %s ..."%output)
            PROFILER.dump_stats(output)
        else:
            self.run_myself()

    def run_myself(self):
        r"""
        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: EX = RESetMPExample(maxl=6)
            sage: EX.setup_workers(1)

            sage: w = EX._workers[0]
            sage: w._todo.append(EX.roots()[0])
            sage: w.run_myself()

            sage: sleep(1)
            sage: w._todo.append(None)

            sage: EX.get_results()
            720*x^6 + 120*x^5 + 24*x^4 + 6*x^3 + 2*x^2 + x + 1

        Cleanups::

            sage: del EX._results, EX._active_tasks, EX._done, EX._workers
        """
        logger.debug("Started")
        mapred = self._mapred
        reduce_init = mapred.reduce_init
        results = mapred._results

        self._stats[0] = 0
        self._stats[3] = 0
        logger.debug("Launching thief")
        self._thief = Thread(target = self._thief, name="Thief")
        self._thief.start()
        self._res = reduce_init()

        try:
            while True:
                try:
                    node = self._todo.pop()
                except IndexError:
                    node = self.steal()
                self.walk_branch_locally(node)
                if self._reduce_locally != True:
                    self.send_partial_result()
        except AbortError:
            logger.debug("Aborted !")
            results.put(self._res)
        results.put(None)
        self._thief.join()
        del self._request
        self._read_task.close()
        self._write_task.close()
        del self._read_task, self._write_task
        del self._mapred
        del self._stats
        logger.debug("Exiting")

    def send_partial_result(self):
        r"""
        Send results to the MapReduce process

        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: EX = RESetMPExample(maxl=4)
            sage: EX.setup_workers(1)
            sage: w = EX._workers[0]
            sage: w._res = 4
            sage: w.send_partial_result()
            sage: w._res
            0
            sage: EX._results.get()
            4
        """
        self._mapred._results.put(self._res)
        self._res = self._mapred.reduce_init()

    def walk_branch_locally(self, node):
        r"""
        EXAMPLES::

            sage: from sage.combinat.map_reduce import RESetMPExample, MapReduceWorker
            sage: EX = RESetMPExample(maxl=4)
            sage: w = MapReduceWorker(EX, 0, True)
            sage: def sync(): pass
            sage: w.synchronize = sync
            sage: w._res = 0

            sage: w.walk_branch_locally([])
            sage: w._res
            x^4 + x^3 + x^2 + x + 1

            sage: w.walk_branch_locally(w._todo.pop())
            sage: w._res
            2*x^4 + x^3 + x^2 + x + 1

            sage: while True: w.walk_branch_locally(w._todo.pop())
            Traceback (most recent call last):
            ...
            IndexError: pop from an empty deque
            sage: w._res
            24*x^4 + 6*x^3 + 2*x^2 + x + 1
        """
        mapred = self._mapred
        children = mapred.children
        post_process = mapred.post_process
        fun  = mapred.map_function
        reduc = mapred.reduce_function

        logger.debug("Working on %s..."%(node,))
        while True:
            res = post_process(node)
            if res is not None:
                self._res = reduc(self._res, fun(res))
            newnodes = iter(children(node))
            try:
                node = newnodes.next()
            except StopIteration:
                return
            for child in newnodes:
                self._todo.append(child)

class RESetMPExample(RESetMapReduce):
    r"""
    An example of map reduce class

    EXAMPLE::

        sage: from sage.combinat.map_reduce import RESetMPExample
        sage: EX = RESetMPExample()
        sage: EX.run()
        362880*x^9 + 40320*x^8 + 5040*x^7 + 720*x^6 + 120*x^5 + 24*x^4 + 6*x^3 + 2*x^2 + x + 1
    """
    def __init__(self, maxl = 9):
        r"""
        TESTS::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: RESetMPExample()
            <sage.combinat.map_reduce.RESetMPExample object at 0x...>
        """
        from sage.calculus.var import var
        self.x = var('x')
        self.maxl = maxl
    def roots(self):
        r"""
        EXAMPLE::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: RESetMPExample().roots()
            [[]]
        """
        return [[]]
    def children(self, l):
        r"""
        EXAMPLE::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: RESetMPExample().children([1,0])
            [[2, 1, 0], [1, 2, 0], [1, 0, 2]]
        """
        return [ l[:i] + [len(l)] + l[i:]
                 for i in range(len(l)+1) ] if len(l) < self.maxl else []
    def map_function(self, z):
        r"""
        EXAMPLE::

            sage: from sage.combinat.map_reduce import RESetMPExample
            sage: RESetMPExample().map_function([1,0])
            x^2
        """
        return self.x**len(z)


class RESetParallelIterator(RESetMapReduce):
    r"""

    EXAMPLE::

        sage: from sage.combinat.map_reduce import RESetParallelIterator
        sage: S = RESetParallelIterator( [[]],
        ....:   lambda l: [l+[0], l+[1]] if len(l) < 15 else [])
        sage: sum(1 for _ in S)
        65535
    """
    def map_function(self, z):
        r"""
        EXAMPLE::

            sage: from sage.combinat.map_reduce import RESetParallelIterator
            sage: S = RESetParallelIterator( [[]],
            ....:   lambda l: [l+[0], l+[1]] if len(l) < 15 else [])
            sage: S.map_function([1, 0])
            ([1, 0],)
        """
        return (z,)

    reduce_init = tuple

    def __iter__(self):
        r"""
        EXAMPLE::

            sage: from sage.combinat.map_reduce import RESetParallelIterator
            sage: S = RESetParallelIterator( [[]],
            ....:   lambda l: [l+[0], l+[1]] if len(l) < 15 else [])
            sage: it = iter(S)
            sage: it.next() # random
            [1, 1, 0]
            sage: it.next() # random
            [1, 1, 0, 1]
            sage: sum(1 for _ in it)
            65533
        """
        self.setup_workers(reduce_locally="sync")
        self.start_workers()
        active_proc = self._nprocess
        while True:
            newres = self._results.get()
            if newres is not None:
                logger.debug("Got some results")
                for r in newres:
                    yield r
            else:
                active_proc -= 1
                if active_proc == 0:
                    break
        self.finish()

